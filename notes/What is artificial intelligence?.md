# What is artificial intelligence?
AI is any technique that enables computers to mimic human behavior. Historically AI has been broken into two branches of study -- symbolic reasoning and machine learning. Machine learning is the dominant branch today due to significant breakthroughs in its subfield deep learning.

To understand how AI has permeated itself into everyday conversation, it's helpful to understand the field's evolution over the last 80 years.
- In 1943, Warren McCulloch and Walter Pitts developed the first mathematical and computer model of the biological neuron.
- In 1950, Alan Turing publishes "Can Machines Think" discussing how to build intelligent machines and how to test their intelligence.
- In 1952, Arthur Samuel, an engineer at IBM, programmed an IBM 704 computer to play a game of checkers. His program implemented an early pruning technique to minimize a loss function similar to today's AI models.
- In 1955 Allen Newell and Herbert Simon created the "Logic Theorist" program, which was capable of solving complex mathematical theorems similar to the human mind. This was the birth of symbolic reasoning and seen as the first functional AI program.
- In 1956 John McCarthy, Marvin Minsky, Nat Rochester, and Claude Shannon host a 12 week workshop at Darthmouth focused on creating intelligent machines. The phrase "artificial intelligence" was born. Their goal was "to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans".
- In 1958 Cornell professor, Frank Rosenblatt, demonstrated the perceptron by teaching an IBM computer to distinguish between position of markings on a card. The perceptron would become the fundamental unit of neural networks.
- In 1966 Joseph Weizenbaum created ELIZA, a symbolic reasoning system, considered to be the first chatbot for humans to have conversation with a computer. It was an early form of Natural Language Processing.
- In 1968 Terry Winograd created SHRDLU, a symbolic reasoning system, which allowed humans to manipulate a virtual world of blocks, boxes, and pyramids with natural language instruction queries. The program demonstrated a machines ability to understand its environment and memorize previous moves.
- In 1974 MYCIN, a symbolic reasoning system, was created at Stanford with the goal of diagnosing and recommending treatment for infections. The system was made of 500 rules, and would ask questions about a patient's symptoms in an attempt to find a possible infection match.
- In 1984 Stanford professor, Douglas Lenat, started building Cyc, a symbolic reasoning system, with the intention of demonstrating common sense understanding of the world in machines. To date Cyc has more than 15 million rules.
- In 1986 AI Godfather, Geoff Hinton, lays out the foundation for backpropagation in his paper "Learning representations by backpropagating errors". This technique is fundamental to training neural networks today.
- In 1990 MIT professor, Rodney Brooks, argued humans don't learn by rules, but from interacting with their environment in his paper “Elephants Don’t Play Chess”. This sparked the "Behavior AI" and robotics movement, leading Brooks to build iRobot, the company behind the Roomba.
- In 1997 a group of IBM researchers built a symbolic reasoning system that beat the current world champion, Garry Kasparov, in chess. The program was capable of considering 200 million possible chess positions per second. This popularized games being used to measure intelligence.
- In 2012 Alex Krizhevsky and Ilya Sutskever, students of Geoff Hinton, created a model trained on GPUs to compete in the ImageNet competition. ImageNet was a dataset of 14 million tagged images created by AI pioneer Fei-Fei Li in 2009. The highest accuracy before was 72%, Alex and Ilya achieved an accuracy of 85%, showing the power of training deep neural nets with GPUs.
- In 2013 Deepmind demonstrated that neural networks can learn through optimizing a reward function -- a technique known as reinforcement learning. They trained a neural network to play a variety of Atari video games and the model's behaviors were rewarded based on what led to a high score.
- In 2016 Deepmind used reinforcement learning to train a neural network to play the game of Chinese Go -- a game considered more complex than chess. AlphaGo, as the model is known, went on to be the world champion, Lee Sedol, four games to one.
- In 2017 a team of researchers at Google released a paper, “Attention is All You Need”, outlining the novel architecture of what would become known as the transformer. This architecture consisted of a process called "attention", which was different than sequential based architectures seen in recurrent neural networks, allowing neural networks to simultaneously read and consider sequential stream of data in relation to the output. As a result, neural networks had a better understanding of context and meaning of a user's input.
- In 2020 OpenAI released GPT3, a 175B parameter transformer based model capable of generating human-like text based on a prompt. It was trained on significantly more data than previous models.  
- In 2022 OpenAI released ChatGPT, a chatbot built on an instruction tuned GPT3 model. ChatGPT quickly grew to 100M users, catalyzing the AI environment we are experiencing today.

## Go deeper
1. [[What is symbolic reasoning?]]
2. [[What is machine learning?]]

## Learning material
1. [The History of AI in 7 Experiments](https://thegeneralist.substack.com/p/the-history-of-ai)
2. [The History of Artificial Intelligence](https://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/)

